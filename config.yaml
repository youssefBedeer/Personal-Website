profile:
  name: "Youssef Bedeer"
  title: "AI/ML Engineer specializing in LLMs & MLOps"
  summary: >
    As an AI Engineer, I specialize in building end-to-end machine learning
    systems that deliver impactful solutions. My expertise spans from data
    preparation and model training to deployment using technologies like
    FastAPI and Docker. Committed to creating production-ready systems, I
    focus on achieving business objectives through reliable and maintainable
    ML applications.
  location: "PortSaid, Egypt"
  # current_role: "AI/ML Engineer @ Company"
  avatar_image: ""  # Optional: path or URL to your profile image
  page_title: "Youssef Bedeer â€“ AI/ML Engineer"

social_links:
  LinkedIn: "https://www.linkedin.com/in/youssef-bedeer-4955b3321/"
  GitHub: "https://github.com/youssefBedeer"
  # Portfolio: "https://your-custom-link.com"

# hero_metrics:
#   - label: "Models in Production"
#     value: "5+"
#     delta: ""
#   - label: "LLM Pipelines Deployed"
#     value: "3"
#     delta: ""
#   - label: "Datasets Processed"
#     value: "10TB+"
#     delta: ""

projects:
  - name: "Telco Customer Churn Prediction â€“ End-to-End ML System"
    tagline: "RAG-based assistant for customer support teams"
    description: >
      Designed and deployed an end-to-end ML system covering 5 core stages
      (ingestion, validation, feature engineering, training, deployment) to
      support proactive customer retention strategies.
      Implemented MLOps workflows using MLflow to track multiple
      experiment runs and model versions, improving reproducibility and
      comparison across iterations.
      Deployed a containerized REST API using FastAPI and Docker, integrated
      with AWS infrastructure and CI/CD pipelines to enable reliable,
      repeatable production releases.
    tech_stack:
      - "Python"
      - "Pandas"
      - "Scikit-learn"
      - "FastAPI"
      - "MLflow"
      - "Docker"
    metrics:
      - "Reduced average handling time by 35%"
      - "Automated 40%+ of repetitive support tickets"
      - "Integrated with Slack and web widget"
    links:
      demo: "https://your-demo-link.com"
      github: "https://github.com/youssefBedeer/End-to-End-TelcoChurn"
    image: "https://www.istockphoto.com/photos/telecommunications"  # Optional: screenshot or GIF path/URL

  - name: "MLOps Pipeline for Computer Vision"
    tagline: "CI/CD for training, evaluation, and deployment"
    description: >
      Designed an MLOps pipeline for training and deploying computer vision models
      with experiment tracking, model registry, and automated validation.
    tech_stack:
      - "Python"
      - "PyTorch"
      - "MLflow"
      - "DVC"
      - "Docker"
      - "GitHub Actions"
    metrics:
      - "Cut model deployment time from weeks to days"
      - "Reproducible experiments with full lineage tracking"
    links:
      demo: ""
      github: "https://github.com/your-handle/cv-mlops-pipeline"
      docs: ""
    image: ""

  - name: "Telco Customer Churn Prediction â€“ End-to-End ML System"
    tagline: "RAG-based assistant for customer support teams"
    description: >
      Designed and deployed an end-to-end ML system covering 5 core stages
      (ingestion, validation, feature engineering, training, deployment) to
      support proactive customer retention strategies.
      Implemented MLOps workflows using MLflow to track multiple
      experiment runs and model versions, improving reproducibility and
      comparison across iterations.
      Deployed a containerized REST API using FastAPI and Docker, integrated
      with AWS infrastructure and CI/CD pipelines to enable reliable,
      repeatable production releases.
    tech_stack:
      - "Python"
      - "Pandas"
      - "Scikit-learn"
      - "FastAPI"
      - "MLflow"
      - "Docker"
    metrics:
      - "Reduced average handling time by 35%"
      - "Automated 40%+ of repetitive support tickets"
      - "Integrated with Slack and web widget"
    links:
      demo: "https://your-demo-link.com"
      github: "https://github.com/youssefBedeer/End-to-End-TelcoChurn"
    image: "https://www.istockphoto.com/photos/telecommunications" 

  - name: "MLOps Pipeline for Computer Vision"
    tagline: "CI/CD for training, evaluation, and deployment"
    description: >
      Designed an MLOps pipeline for training and deploying computer vision models
      with experiment tracking, model registry, and automated validation.
    tech_stack:
      - "Python"
      - "PyTorch"
      - "MLflow"
      - "DVC"
      - "Docker"
      - "GitHub Actions"
    metrics:
      - "Cut model deployment time from weeks to days"
      - "Reproducible experiments with full lineage tracking"
    links:
      demo: ""
      github: "https://github.com/your-handle/cv-mlops-pipeline"
      docs: ""
    image: ""

  - name: "Telco Customer Churn Prediction â€“ End-to-End ML System"
    tagline: "RAG-based assistant for customer support teams"
    description: >
      Designed and deployed an end-to-end ML system covering 5 core stages
      (ingestion, validation, feature engineering, training, deployment) to
      support proactive customer retention strategies.
      Implemented MLOps workflows using MLflow to track multiple
      experiment runs and model versions, improving reproducibility and
      comparison across iterations.
      Deployed a containerized REST API using FastAPI and Docker, integrated
      with AWS infrastructure and CI/CD pipelines to enable reliable,
      repeatable production releases.
    tech_stack:
      - "Python"
      - "Pandas"
      - "Scikit-learn"
      - "FastAPI"
      - "MLflow"
      - "Docker"
    metrics:
      - "Reduced average handling time by 35%"
      - "Automated 40%+ of repetitive support tickets"
      - "Integrated with Slack and web widget"
    links:
      demo: "https://your-demo-link.com"
      github: "https://github.com/youssefBedeer/End-to-End-TelcoChurn"
    image: "https://www.istockphoto.com/photos/telecommunications" 

skills:
  "Languages & Core":
    items:
      - name: "Python"
        level: "Intermediate"
        years: 2
      - name: "SQL"
        level: "Beginner"
        years: 1


  "Machine Learning":
    items:
      - name: "Supervised & Unsupervised Learning"
        level: "Intermediate"
        years: 2
      - name: "Deep Learning (CNNs, RNNs, Transformers)"
        level: "Intermediate"
        years: 2


  "LLMs & NLP":
    items:
      - name: "RAG Systems"
        level: "Intermediate"
        years: 1
      - name: "Vector Databases (FAISS, Pinecone, etc.)"
        level: "Intermediate"
        years: 1
      - name: "Text Processing (Tokenization, Embeddings, etc.)"
        level: "Intermediate"
        years: 1

  "MLOps & Data":
    items:
      - name: "Model Deployment"
        level: "Intermediate"
      - name: "Experiment Tracking"
        level: "Beginner"
      - name: "Containers & Cloud (Docker, AWS)"
        level: "Beginner"

contact:
  email: "youssef1bedeer@gmail.com"
  location: "PortSaid, Egypt"
  availability: "Open to opportunities"
  phone_1: "01226627188"
  phone_2: "01203086536"
  calendly: ""  # Optional: link to scheduling page

blog_posts:
  - title: "Telco Customer Churn Prediction - End-to-End ML Project"
    date: "2026-01-13"
    tags:
      - "ML"
      - "MLOps"
    content: |
      # ğŸ“ Telco Customer Churn Prediction - End-to-End ML Project

      [![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
      [![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
      [![XGBoost](https://img.shields.io/badge/XGBoost-Optimized-orange)](https://xgboost.readthedocs.io/)
      [![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

      > **A production-ready machine learning system for predicting customer churn in telecommunications using XGBoost, MLflow experiment tracking, and modular pipeline architecture.**

      ---

      ## ğŸ“‹ Table of Contents

      - [Overview](#-overview)
      - [Key Features](#-key-features)
      - [Project Architecture](#-project-architecture)
      - [Tech Stack](#-tech-stack)
      - [Installation](#-installation)
      - [Usage](#-usage)
      - [Project Structure](#-project-structure)
      - [ML Pipeline Stages](#-ml-pipeline-stages)
      - [MLflow Integration](#-mlflow-integration)
      - [API Deployment](#-api-deployment)
      - [AWS Deployment](#-aws-deployment)
      - [Configuration](#-configuration)
      - [Contributing](#-contributing)
      - [License](#-license)

      ---

      ## ğŸ¯ Overview

      This project implements an **end-to-end machine learning solution** to predict customer churn for a telecommunications company. The system uses advanced ML techniques including hyperparameter optimization with Optuna, experiment tracking with MLflow, and a modular pipeline architecture for production deployment.

      ### Business Problem
      Customer churn is a critical metric for telecom companies. Identifying customers likely to churn enables proactive retention strategies, reducing revenue loss and improving customer lifetime value.

      ### Solution
      A production-grade ML pipeline that:
      - Processes customer data through automated validation and transformation
      - Trains optimized XGBoost models using Bayesian hyperparameter tuning
      - Tracks experiments and model versions with MLflow
      - Provides REST API endpoints for real-time predictions
      - Supports deployment on AWS with CI/CD automation

      ---

      ## âœ¨ Key Features

      - **ğŸ”„ Modular Pipeline Architecture**: Separate stages for ingestion, validation, transformation, and training
      - **ğŸ¯ Advanced Model Optimization**: Optuna-based hyperparameter tuning for XGBoost
      - **ğŸ“Š Experiment Tracking**: MLflow integration for model versioning and metrics logging
      - **âœ… Data Validation**: Schema validation to ensure data quality
      - **ğŸ”§ Configuration Management**: YAML-based configuration for easy customization
      - **ğŸš€ Multiple Deployment Options**: Flask, FastAPI, Streamlit, and Gradio support
      - **â˜ï¸ Cloud Ready**: AWS deployment with Docker and GitHub Actions CI/CD
      - **ğŸ“ˆ Model Monitoring**: Comprehensive evaluation metrics and logging

      ---

      ## ğŸ—ï¸ Project Architecture

      ```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Data Source    â”‚
      â”‚   (CSV/API)     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Data Ingestion  â”‚ â”€â”€â–º Download & Extract Data
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Data Validation â”‚ â”€â”€â–º Schema & Quality Checks
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Transformation  â”‚ â”€â”€â–º Preprocessing & Feature Engineering
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Model Training  â”‚ â”€â”€â–º XGBoost + Optuna Optimization
      â”‚   + MLflow      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Model Registry  â”‚ â”€â”€â–º Versioned Models
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  API Service    â”‚ â”€â”€â–º FastAPI/Flask Endpoints
      â”‚  (Prediction)   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      ```

      ---

      ## ğŸ› ï¸ Tech Stack

      ### Machine Learning & Data Science
      - **scikit-learn** `>=1.3.0` - ML utilities and preprocessing
      - **XGBoost** `>=1.7.5` - Gradient boosting framework
      - **LightGBM** `>=4.3.0` - Alternative gradient boosting
      - **TensorFlow** `>=2.19.0` - Deep learning framework
      - **Optuna** `>=3.4.0` - Hyperparameter optimization
      - **pandas** `>=2.0.0` - Data manipulation
      - **numpy** `>=1.25.0` - Numerical computing

      ### MLOps & Tracking
      - **MLflow** `>=2.2.2` - Experiment tracking and model registry
      - **DVC** `>=2.50.0` - Data version control
      - **DagsHub** - Remote MLflow tracking server

      ### Web Frameworks & APIs
      - **FastAPI** `>=0.110.0` - Modern async API framework *(Planned)*
      - **Flask** `>=2.3.0` - Lightweight web framework
      - **Uvicorn** `>=0.29.0` - ASGI server for FastAPI
      - **Streamlit** `>=1.36.0` - Interactive dashboards
      - **Gradio** `>=4.29.0` - ML model interfaces

      ### DevOps & Deployment
      - **Docker** - Containerization
      - **GitHub Actions** - CI/CD automation
      - **AWS EC2** - Cloud compute
      - **AWS ECR** - Container registry

      ---

      ## ğŸ“¥ Installation

      ### Prerequisites
      - Python 3.8 or higher
      - Git
      - (Optional) Conda for environment management

      ### Step 1: Clone the Repository

      ```bash
      git clone https://github.com/youssefBedeer/End-to-End-TelcoChurn.git
      cd End-to-End-TelcoChurn
      ```

      ### Step 2: Create Virtual Environment

      **Option A: Using Conda**
      ```bash
      conda create -n telco-churn python=3.8 -y
      conda activate telco-churn
      ```

      **Option B: Using venv**
      ```bash
      python -m venv venv
      # Windows
      venv\Scripts\activate
      # Linux/Mac
      source venv/bin/activate
      ```

      ### Step 3: Install Dependencies

      ```bash
      pip install -r requirements.txt
      ```

      ---

      ## ğŸš€ Usage

      ### Training the Model

      Run the complete ML pipeline:

      ```bash
      python main.py
      ```

      This executes all pipeline stages:
      1. **Data Ingestion** - Downloads and extracts the dataset
      2. **Data Validation** - Validates schema and data quality
      3. **Data Transformation** - Preprocesses features and splits data
      4. **Model Training** - Trains XGBoost with hyperparameter optimization

      ### Running the Web Application

      **Flask Application** (Current)
      ```bash
      python app.py
      ```

      **FastAPI Application** (Planned)
      ```bash
      uvicorn app:app --reload --host 0.0.0.0 --port 8000
      ```

      **Streamlit Dashboard**
      ```bash
      streamlit run app.py
      ```

      **Gradio Interface**
      ```bash
      python app.py  # If using Gradio
      ```

      ### Making Predictions

      Once the API is running, send POST requests with customer data:

      ```python
      import requests

      # Example customer data
      customer_data = {
          "gender": "Female",
          "SeniorCitizen": 0,
          "Partner": "Yes",
          "Dependents": "No",
          "tenure": 12,
          "PhoneService": "Yes",
          "MultipleLines": "No",
          "InternetService": "Fiber optic",
          "OnlineSecurity": "No",
          "OnlineBackup": "Yes",
          "DeviceProtection": "No",
          "TechSupport": "No",
          "StreamingTV": "Yes",
          "StreamingMovies": "No",
          "Contract": "Month-to-month",
          "PaperlessBilling": "Yes",
          "PaymentMethod": "Electronic check",
          "MonthlyCharges": 70.35,
          "TotalCharges": "1397.475"
      }

      response = requests.post("http://localhost:8000/predict", json=customer_data)
      print(response.json())
      ```

      ---

      ## ğŸ“ Project Structure

      ```
      End-to-End-TelcoChurn/
      â”‚
      â”œâ”€â”€ artifacts/                      # Generated artifacts (models, data, etc.)
      â”‚   â”œâ”€â”€ data_ingestion/            # Raw and extracted data
      â”‚   â”œâ”€â”€ data_validation/           # Validation reports
      â”‚   â”œâ”€â”€ data_transformation/       # Preprocessed data and transformers
      â”‚   â””â”€â”€ model_trainer/             # Trained models
      â”‚
      â”œâ”€â”€ config/                         # Configuration files
      â”‚   â””â”€â”€ config.yaml                # Main configuration
      â”‚
      â”œâ”€â”€ src/                           # Source code
      â”‚   â”œâ”€â”€ components/                # Pipeline components
      â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
      â”‚   â”‚   â”œâ”€â”€ data_validation.py
      â”‚   â”‚   â”œâ”€â”€ data_transformation.py
      â”‚   â”‚   â””â”€â”€ model_trainer.py
      â”‚   â”‚
      â”‚   â”œâ”€â”€ pipeline/                  # Pipeline stages
      â”‚   â”‚   â”œâ”€â”€ stage_01_data_ingestion.py
      â”‚   â”‚   â”œâ”€â”€ stage_02_data_validation.py
      â”‚   â”‚   â”œâ”€â”€ stage_03_data_transformation.py
      â”‚   â”‚   â””â”€â”€ stage_04_model_trainer.py
      â”‚   â”‚
      â”‚   â”œâ”€â”€ config/                    # Configuration manager
      â”‚   â”œâ”€â”€ entity/                    # Data classes and entities
      â”‚   â”œâ”€â”€ utils/                     # Utility functions
      â”‚   â””â”€â”€ __init__.py               # Logging and exception handling
      â”‚
      â”œâ”€â”€ research/                      # Jupyter notebooks for experimentation
      â”œâ”€â”€ templates/                     # HTML templates for web UI
      â”œâ”€â”€ logs/                         # Application logs
      â”‚
      â”œâ”€â”€ main.py                       # Main training pipeline
      â”œâ”€â”€ app.py                        # Web application (Flask/FastAPI)
      â”œâ”€â”€ params.yaml                   # Hyperparameter search space
      â”œâ”€â”€ schema.yaml                   # Data schema definition
      â”œâ”€â”€ best_params.yaml              # Optimized hyperparameters
      â”œâ”€â”€ requirements.txt              # Python dependencies
      â”œâ”€â”€ Dockerfile                    # Docker configuration
      â”œâ”€â”€ setup.py                      # Package setup
      â””â”€â”€ README.md                     # This file
      ```

      ---

      ## ğŸ”„ ML Pipeline Stages

      ### 1ï¸âƒ£ Data Ingestion
      - Downloads dataset from remote source
      - Extracts and stores raw data
      - **Output**: `artifacts/data_ingestion/Telco-Customer-Churn.csv`

      ### 2ï¸âƒ£ Data Validation
      - Validates column names and data types against schema
      - Checks for data quality issues
      - **Output**: `artifacts/data_validation/status.txt`

      ### 3ï¸âƒ£ Data Transformation
      - Handles missing values and outliers
      - Encodes categorical features
      - Scales numerical features
      - Splits data into train/test sets
      - **Output**: Preprocessor, train/test arrays

      ### 4ï¸âƒ£ Model Training
      - Hyperparameter optimization using Optuna
      - Trains XGBoost classifier
      - Logs metrics and parameters to MLflow
      - Saves best model
      - **Output**: `artifacts/model_trainer/model.joblib`

      ---

      ## ğŸ“Š MLflow Integration

      ### Local MLflow UI

      Start the MLflow tracking UI:

      ```bash
      mlflow ui
      ```

      Access at: `http://localhost:5000`

      ### Remote Tracking with DagsHub

      Set environment variables for remote tracking:

      **Windows (CMD)**
      ```cmd
      set MLFLOW_TRACKING_URI=https://dagshub.com/youssefBedeer/End-to-End-TelcoChurn.mlflow
      set MLFLOW_TRACKING_USERNAME=youssefBedeer
      set MLFLOW_TRACKING_PASSWORD=your_token_here
      ```

      **Linux/Mac**
      ```bash
      export MLFLOW_TRACKING_URI=https://dagshub.com/youssefBedeer/End-to-End-TelcoChurn.mlflow
      export MLFLOW_TRACKING_USERNAME=youssefBedeer
      export MLFLOW_TRACKING_PASSWORD=your_token_here
      ```

      ### MLflow Features Used
      - **Experiment Tracking**: Log parameters, metrics, and artifacts
      - **Model Registry**: Version control for trained models
      - **Artifact Storage**: Store models, plots, and data
      - **Comparison**: Compare multiple runs and experiments

      ---

      ## ğŸŒ API Deployment

      ### FastAPI Implementation (Planned)

      The project will support FastAPI for production-grade API deployment:

      **Features:**
      - âœ… Async request handling
      - âœ… Automatic API documentation (Swagger/ReDoc)
      - âœ… Data validation with Pydantic
      - âœ… High performance with Uvicorn
      - âœ… CORS support for web integration

      **Endpoints:**
      - `GET /` - Health check
      - `POST /predict` - Single prediction
      - `POST /predict/batch` - Batch predictions
      - `GET /model/info` - Model metadata

      **Example FastAPI Structure:**
      ```python
      from fastapi import FastAPI
      from pydantic import BaseModel

      app = FastAPI(title="Telco Churn Prediction API")

      class CustomerData(BaseModel):
          gender: str
          SeniorCitizen: int
          Partner: str
          # ... other features

      @app.post("/predict")
      async def predict_churn(customer: CustomerData):
          # Load model and make prediction
          return {"churn_probability": 0.75, "will_churn": True}
      ```

      ---

      ## â˜ï¸ AWS Deployment

      ### Prerequisites
      1. AWS Account
      2. AWS CLI configured
      3. Docker installed

      ### Deployment Steps

      #### 1. Create IAM User
      Create an IAM user with the following policies:
      - `AmazonEC2ContainerRegistryFullAccess`
      - `AmazonEC2FullAccess`

      #### 2. Create ECR Repository
      ```bash
      aws ecr create-repository --repository-name telco-churn
      ```

      Save the repository URI (e.g., `566373416292.dkr.ecr.ap-south-1.amazonaws.com/telco-churn`)

      #### 3. Launch EC2 Instance
      - Choose Ubuntu AMI
      - Instance type: t2.medium or larger
      - Configure security groups (open ports 22, 80, 8000)

      #### 4. Install Docker on EC2
      ```bash
      sudo apt-get update -y
      sudo apt-get upgrade -y
      curl -fsSL https://get.docker.com -o get-docker.sh
      sudo sh get-docker.sh
      sudo usermod -aG docker ubuntu
      newgrp docker
      ```

      #### 5. Configure GitHub Secrets
      Add the following secrets to your GitHub repository:
      - `AWS_ACCESS_KEY_ID`
      - `AWS_SECRET_ACCESS_KEY`
      - `AWS_REGION` (e.g., `us-east-1`)
      - `AWS_ECR_LOGIN_URI` (e.g., `566373416292.dkr.ecr.ap-south-1.amazonaws.com`)
      - `ECR_REPOSITORY_NAME` (e.g., `telco-churn`)

      #### 6. Setup Self-Hosted Runner
      In GitHub repository:
      1. Go to Settings â†’ Actions â†’ Runners
      2. Click "New self-hosted runner"
      3. Follow instructions to configure on EC2

      #### 7. Deploy via GitHub Actions
      Push to main branch to trigger automatic deployment:
      ```bash
      git push origin main
      ```

      ---

      ## âš™ï¸ Configuration

      ### config.yaml
      Main configuration file for pipeline stages:
      ```yaml
      artifacts_root: artifacts

      data_ingestion:
        root_dir: artifacts/data_ingestion
        source_url: <data_source_url>
        
      model_trainer:
        root_dir: artifacts/model_trainer
        THRESHOLD: 0.30  # Classification threshold
      ```

      ### params.yaml
      Hyperparameter search space for Optuna:
      ```yaml
      xgboost_params:
        n_estimators:
          type: int
          low: 300
          high: 800
        learning_rate:
          type: float
          low: 0.01
          high: 0.2
        max_depth:
          type: int
          low: 3
          high: 10
      ```

      ### schema.yaml
      Data schema validation:
      ```yaml
      COLUMNS:
        gender: object
        SeniorCitizen: int64
        tenure: int64
        MonthlyCharges: float64
        Churn: object

      TARGET_COLUMN:
        name: Churn
      ```

      ---

      ## ğŸ” Model Performance

      The model is optimized using Optuna with the following metrics:
      - **Accuracy**: Overall prediction accuracy
      - **Precision**: Precision for churn class
      - **Recall**: Recall for churn class
      - **F1-Score**: Harmonic mean of precision and recall
      - **ROC-AUC**: Area under the ROC curve
      - **Log Loss**: Logarithmic loss

      Custom threshold (default: 0.30) is used to optimize for business objectives.

      ---

      ## ğŸ§ª Testing

      Run tests (when implemented):
      ```bash
      pytest tests/
      ```

      ---

      ## ğŸ“ Development Workflow

      1. **Update Configuration**: Modify `config.yaml`, `schema.yaml`, `params.yaml`
      2. **Update Entities**: Define data classes in `src/entity/`
      3. **Update Config Manager**: Modify `src/config/configuration.py`
      4. **Update Components**: Implement logic in `src/components/`
      5. **Update Pipelines**: Create pipeline stages in `src/pipeline/`
      6. **Update Main**: Integrate stages in `main.py`
      7. **Update App**: Add API endpoints in `app.py`

      ---

      ## ğŸ¤ Contributing

      Contributions are welcome! Please follow these steps:

      1. Fork the repository
      2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
      3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
      4. Push to the branch (`git push origin feature/AmazingFeature`)
      5. Open a Pull Request

      ---

      ## ğŸ“„ License

      This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

      ---

      ## ğŸ‘¤ Author

      **Youssef Bedeer**
      - GitHub: [@youssefBedeer](https://github.com/youssefBedeer)
      - DagsHub: [youssefBedeer](https://dagshub.com/youssefBedeer)

      ---

      ## ğŸ™ Acknowledgments

      - Dataset: Telco Customer Churn Dataset
      - MLflow for experiment tracking
      - Optuna for hyperparameter optimization
      - XGBoost team for the excellent gradient boosting library

      ---

      ## ğŸ“š Additional Resources

      - [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
      - [XGBoost Documentation](https://xgboost.readthedocs.io/)
      - [FastAPI Documentation](https://fastapi.tiangolo.com/)
      - [Optuna Documentation](https://optuna.readthedocs.io/)

      ---

      ## ğŸ—ºï¸ Roadmap

      - [x] Basic ML pipeline implementation
      - [x] MLflow integration
      - [x] Hyperparameter optimization with Optuna
      - [x] Docker containerization
      - [x] AWS deployment setup
      - [ ] **FastAPI implementation** *(In Progress)*
      - [ ] Batch prediction endpoints
      - [ ] Model monitoring dashboard
      - [ ] A/B testing framework
      - [ ] Automated retraining pipeline
      - [ ] Feature importance visualization
      - [ ] SHAP values for model interpretability

      ---

      <div align="center">

      **â­ If you find this project useful, please consider giving it a star! â­**

      Made with â¤ï¸ by Youssef Bedeer

      </div>

  - title: "From Notebook to Production: MLOps for Busy ML Engineers"
    date: "2025-06-01"
    tags:
      - "MLOps"
      - "Best Practices"
    content: |
      ## From Notebook to Production: MLOps for Busy ML Engineers

      Another placeholder blog post. Use this section to describe your real
      experience taking models from experimentation to production.

      You can include:

      - Your typical pipeline (data, training, evaluation, deployment)
      - Tools you use (MLflow, Docker, CI/CD, etc.)
      - Lessons learned and best practices

  - title: "From Notebook to Production: MLOps for Busy ML Engineers"
    date: "2025-06-01"
    tags:
      - "MLOps"
      - "Best Practices"
    content: |
      ## From Notebook to Production: MLOps for Busy ML Engineers

      Another placeholder blog post. Use this section to describe your real
      experience taking models from experimentation to production.

      You can include:

      - Your typical pipeline (data, training, evaluation, deployment)
      - Tools you use (MLflow, Docker, CI/CD, etc.)
      - Lessons learned and best practices

  - title: "From Notebook to Production: MLOps for Busy ML Engineers"
    date: "2025-06-01"
    tags:
      - "MLOps"
      - "Best Practices"
    content: |
      ## From Notebook to Production: MLOps for Busy ML Engineers

      Another placeholder blog post. Use this section to describe your real
      experience taking models from experimentation to production.

      You can include:

      - Your typical pipeline (data, training, evaluation, deployment)
      - Tools you use (MLflow, Docker, CI/CD, etc.)
      - Lessons learned and best practices

  - title: "From Notebook to Production: MLOps for Busy ML Engineers"
    date: "2025-06-01"
    tags:
      - "MLOps"
      - "Best Practices"
    content: |
      ## From Notebook to Production: MLOps for Busy ML Engineers

      Another placeholder blog post. Use this section to describe your real
      experience taking models from experimentation to production.

      You can include:

      - Your typical pipeline (data, training, evaluation, deployment)
      - Tools you use (MLflow, Docker, CI/CD, etc.)
      - Lessons learned and best practices

